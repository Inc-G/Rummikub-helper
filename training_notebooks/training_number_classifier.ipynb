{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Get access to google drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# To organize directories\n",
    "import shutil\n",
    "\n",
    "# For metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('drive/MyDrive/')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'predict_numbers/train_numbers'\n",
    "VAL_DIR = 'predict_numbers/val_numbers'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (96, 96)\n",
    "VAL_BATCHES = 10\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(TRAIN_DIR, image_size=IMG_SIZE)\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(VAL_DIR, batch_size=VAL_BATCHES, image_size=IMG_SIZE)\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(image, vector):\n",
    "    return image, tf.one_hot(vector, 14)\n",
    "\n",
    "encoded_ds_train = train_dataset.map(encode_labels)\n",
    "encoded_ds_val = val_dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBrightness(tf.keras.layers.Layer):\n",
    "    def __init__(self, top_brightness, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.top_brightness = top_brightness\n",
    "    def call(self, x):\n",
    "        br = tf.random.uniform([1], minval=0, maxval=self.top_brightness, dtype=tf.dtypes.float32)[0]\n",
    "        return tf.image.adjust_brightness(x, br)\n",
    "\n",
    "class DataAug(tf.keras.Model):\n",
    "    def __init__(self, brightness=.28, **kwargs):\n",
    "        super().__init__()\n",
    "        self.transformations = [tf.keras.layers.RandomTranslation(0.1, 0.1, fill_mode='nearest'),\n",
    "                                tf.keras.layers.RandomZoom((-0.2, 0.2), fill_mode='nearest'), RandomBrightness(brightness),\n",
    "                                tf.keras.layers.RandomRotation(0.5, fill_mode='nearest')]  \n",
    "    def call(self, x):\n",
    "        for t in self.transformations:\n",
    "            x = t(x)\n",
    "        return x\n",
    "\n",
    "data_aug = DataAug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model = tf.keras.applications.MobileNetV2(input_shape=list(IMG_SIZE)+[3], include_top=False, weights='imagenet')\n",
    "pred_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, base_model=pred_model):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.data_aug = data_aug\n",
    "        self.rescaling = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "        self.base_model = pred_model\n",
    "        self.predition_head = [tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                               tf.keras.layers.Dense(32, activation='relu'),\n",
    "                              tf.keras.layers.Dense(14, activation='softmax')]\n",
    "\n",
    "    def call(self, x, data_aug=True):\n",
    "        if data_aug:\n",
    "            x = self.data_aug(x) \n",
    "        x = self.rescaling(x)\n",
    "        x = self.base_model(x, training=False)\n",
    "        for layer in self.predition_head:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_save(tf.keras.Model):\n",
    "    def __init__(self, base_model=pred_model):\n",
    "        super(MyModel_save, self).__init__()\n",
    "        self.base_model = pred_model\n",
    "        self.predition_head = [tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                               tf.keras.layers.Dense(32, activation='relu'),\n",
    "                              tf.keras.layers.Dense(14, activation='softmax')]\n",
    "\n",
    "    def call(self, x, data_aug=True):\n",
    "        x = self.base_model(x, training=False)\n",
    "        for layer in self.predition_head:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "model_save = MyModel_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(np.zeros((3,96, 96, 3)), data_aug=False)\n",
    "model_save(np.zeros((3,96, 96, 3)), data_aug=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot_cm(cm, my_labels=class_names, title=''):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix. Title is the title of the plot (string), and my_labels is\n",
    "    a list of labels for x and y axis\n",
    "    \"\"\"\n",
    "    l = len(my_labels)\n",
    "    fig = plt.figure(figsize = (7,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    color = plt.cm.summer\n",
    "    cax = ax.matshow(cm, cmap = color)\n",
    "    for i in range(len(my_labels)):\n",
    "        for j in range(len(my_labels)):\n",
    "            c = cm[j,i].round(2)\n",
    "            ax.text(i, j, str(c), va='center', ha='center', color='red')\n",
    "    plt.grid(False)\n",
    "    ax.title.set_text(title)\n",
    "    ax.set_yticks(range(l))\n",
    "    ax.set_xticks(range(l))\n",
    "    ax.set_xticklabels(labels=my_labels)\n",
    "    ax.set_yticklabels(labels=my_labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def gradient_step(X, y, my_model, return_loss=True, my_optimizer=optimizer):\n",
    "    \"\"\"\n",
    "    Perform a step of gradient descent updating the loss if past_loss is passed (past_loss != None).\n",
    "    X,y have to be encoded\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = my_model(X)\n",
    "        my_loss = loss_fn(y, predictions)\n",
    "            \n",
    "    grads = tape.gradient(my_loss, my_model.trainable_variables)\n",
    "    my_optimizer.apply_gradients(zip(grads, my_model.trainable_variables))\n",
    "    if return_loss:\n",
    "        return my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "EPOCHS = 15\n",
    "STEPS_PER_EPOCH = 50\n",
    "VAL_BATCH_SIZE = 20\n",
    "\n",
    "past_loss = []\n",
    "past_loss_val = []\n",
    "accuracy_scores = []\n",
    "max_acc_score = .9\n",
    "c_report = 0\n",
    "\n",
    "batched_ds = encoded_ds_train.prefetch(buffer_size=AUTOTUNE)\n",
    "batched_ds_val = encoded_ds_val.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def training_loop(my_model=model, my_optimizer=optimizer, batched_ds=batched_ds, batched_ds_val=batched_ds_val,\n",
    "                  epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, val_batches=VAL_BATCH_SIZE,\n",
    "                  save_model_at_checkpoint=False, model_for_saving=None,\n",
    "                  past_loss=past_loss, past_loss_val=past_loss_val, decay_lr=1.,\n",
    "                  accuracy_scores=accuracy_scores, max_acc_score=max_acc_score, c_report=c_report, classes=class_names):\n",
    "    '''\n",
    "    Training loop for classification.\n",
    "    '''\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print('###########################')\n",
    "        print('Epoch', epoch)\n",
    "        print('---------------------------')\n",
    "\n",
    "        ## Gradient step\n",
    "        for X_batch, y_batch in batched_ds.take(steps_per_epoch):\n",
    "            new_loss = gradient_step(X_batch, y_batch, my_model=my_model, my_optimizer=my_optimizer)\n",
    "            past_loss.append(new_loss)\n",
    "\n",
    "        my_optimizer.learning_rate = my_optimizer.learning_rate*decay_lr\n",
    "\n",
    "        ## Validation\n",
    "        predictions = []\n",
    "        true_results = []\n",
    "        for X_batch, y_batch in batched_ds_val.take(val_batches):\n",
    "            y_pred = model(X_batch, data_aug=False)\n",
    "            if len(predictions) != 0:\n",
    "                predictions = np.concatenate((predictions, y_pred.numpy()))\n",
    "            else:\n",
    "                predictions = y_pred.numpy()\n",
    "\n",
    "            if len(true_results) == 0:\n",
    "                true_results = y_batch.numpy()\n",
    "            else:\n",
    "                true_results = np.concatenate((true_results, y_batch.numpy()))\n",
    "\n",
    "            new_loss_val = loss_fn(y_batch, y_pred)\n",
    "            past_loss_val.append(new_loss_val)\n",
    "\n",
    "        ## Plot loss\n",
    "        loss1 = pd.DataFrame(past_loss, columns = ['train loss'])\n",
    "        loss2 = pd.DataFrame(past_loss_val, columns = ['validation loss'])\n",
    "\n",
    "        newdf = pd.DataFrame(np.repeat(loss2.values, STEPS_PER_EPOCH//VAL_BATCHES, axis=0))\n",
    "        newdf.columns = loss2.columns\n",
    "        loss_df = loss1.join(newdf)\n",
    "        loss_df.plot(figsize = (18,12))\n",
    "        plt.show()\n",
    "    \n",
    "        rolling_loss = loss_df.rolling(window=50).mean().dropna()\n",
    "        rolling_loss.columns = ['rolling loss train', 'rolling loss validation']\n",
    "        rolling_loss.plot(figsize = (18,12))\n",
    "        plt.show()\n",
    "\n",
    "        ## Metrics ##\n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(true_results.argmax(axis=1), predictions.argmax(axis=1), normalize='true', labels=range(len(classes)))\n",
    "        my_plot_cm(cm, my_labels=class_names, title='Confusion matrix validation set')\n",
    "\n",
    "        # Print classification report\n",
    "        print('---------------------')\n",
    "        print('Classification report validation:')\n",
    "        print('Previous epoch:')\n",
    "        print(c_report)\n",
    "        print('Current epoch')\n",
    "        c_report = classification_report(true_results.argmax(axis=1), predictions.argmax(axis=1),labels=range(len(classes)), target_names=classes)\n",
    "        print(c_report)\n",
    "        print('---------------------')\n",
    "\n",
    "        # Plot accuracy score\n",
    "        new_accuracy_score = accuracy_score(true_results.argmax(axis=1), predictions.argmax(axis=1))\n",
    "        print('Latest accuracy score:', new_accuracy_score)\n",
    "        print('---------------------')\n",
    "        accuracy_scores.append(new_accuracy_score)\n",
    "        acc = pd.DataFrame(accuracy_scores, columns = ['accuracy score'])\n",
    "        acc.plot(figsize=(18,12))\n",
    "        plt.show()\n",
    "\n",
    "        ## Checkpoints\n",
    "        if save_model_at_checkpoint:\n",
    "            if new_accuracy_score > max_acc_score:\n",
    "                max_acc_score = new_accuracy_score\n",
    "                print('**********************')\n",
    "                print('New best accuracy score:', new_accuracy_score)\n",
    "                print('**********************')\n",
    "                model_for_saving.set_weights(my_model.get_weights())\n",
    "                model_for_saving.save('accuracy'+str(max_acc_score))\n",
    "                               \n",
    "if False: \n",
    "    training_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.trainable = True\n",
    "for layer in pred_model.layers[:75]:\n",
    "    layer.trainable = False\n",
    "\n",
    "current_lr = optimizer.lr\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(momentum=.9, learning_rate=current_lr/100)\n",
    "\n",
    "if False: \n",
    "    training_loop(epochs=60, decay_lr=0.98,\n",
    "                  my_optimizer=optimizer, model_for_saving=model_save,\n",
    "                  save_model_at_checkpoint=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
